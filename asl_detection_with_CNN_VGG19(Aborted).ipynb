{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "486d1a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:54:34.893333Z",
     "iopub.status.busy": "2022-12-19T10:54:34.892872Z",
     "iopub.status.idle": "2022-12-19T10:54:42.029526Z",
     "shell.execute_reply": "2022-12-19T10:54:42.028487Z",
     "shell.execute_reply.started": "2022-12-19T10:54:34.893234Z"
    }
   },
   "outputs": [],
   "source": [
    "# to subpress warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# The OS module in Python provides functions for interacting with the operating system.\n",
    "import os\n",
    "\n",
    "# Matplotlib is a data visualization and graphical plotting library for Python.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn is alse a data visualization and graphical plotting library for Python.\n",
    "import seaborn as sn\n",
    "\n",
    "# Used to display markdown,image,control (frontend utilities)\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# NumPy is a Python library used for working with arrays\n",
    "import numpy as np\n",
    "\n",
    "# used to split dataset(features and target) into test and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffle the dataset for a even mixture of each type of feature and target.it gives better result.\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Computer vision library\n",
    "import cv2\n",
    "\n",
    "# Used to manipulate different parts of the Python runtime environment.\n",
    "import sys\n",
    "\n",
    "# An open-source framework for building pipelines to perform computer vision inference.\n",
    "import mediapipe as mp\n",
    "\n",
    "# Time module provide time-related functions\n",
    "import time\n",
    "\n",
    "# Used to generate random numbers\n",
    "import random\n",
    "\n",
    "from math import log10, sqrt\n",
    "# for mathematical operations\n",
    "\n",
    "# Keras is a library that provides a Python interface for artificial neural networks. \n",
    "# Keras acts as an interface for the TensorFlow library.\n",
    "import keras\n",
    "\n",
    "# 1. Keras layers are the building blocks of the Keras library that can be stacked together for creating neural network models.\n",
    "# 2. Keras Conv2D creates a 2D convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n",
    "# 3. maxpooling2D Downsamples the input along its spatial dimensions by taking the maximum value over an input window for each channel of the input. \n",
    "# 4 .Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. \n",
    "# 5 .Dropout regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data.\n",
    "# 6. Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. \n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization,Input\n",
    "\n",
    "#  Model groups layers into an object with training and inference features.\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Optimizers are the extended class, which include added information to train a specific model.  \n",
    "# The optimizers are used for improving speed and performance for training a specific model.\n",
    "# Adam is a stochastic gradient descent method based on adaptive estimation of first-order and second-order moments.\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# importing Sqquential model\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "# tensorflow.keras.callbacks is used to visualize training of a model.\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint \n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd9df43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:54:47.097492Z",
     "iopub.status.busy": "2022-12-19T10:54:47.096511Z",
     "iopub.status.idle": "2022-12-19T10:54:47.102835Z",
     "shell.execute_reply": "2022-12-19T10:54:47.101406Z",
     "shell.execute_reply.started": "2022-12-19T10:54:47.097455Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH=r\"/kaggle/input/asl-dataset/asl_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590bb93b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:54:49.819348Z",
     "iopub.status.busy": "2022-12-19T10:54:49.818948Z",
     "iopub.status.idle": "2022-12-19T10:54:49.834304Z",
     "shell.execute_reply": "2022-12-19T10:54:49.833077Z",
     "shell.execute_reply.started": "2022-12-19T10:54:49.819313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading data from CSV and preprocessing\n",
    "dataset_path=r\"/kaggle/input/d/tirtharajsinha/asl-dataset/dataset.csv\"\n",
    "def load_CSV(dataset):\n",
    "    # read data from CSV\n",
    "    rows = open(dataset,\"r\").readlines()\n",
    "    totalImage=len(rows)\n",
    "    \n",
    "    filenames=[]\n",
    "    data=[]\n",
    "    targets=[]\n",
    "    tempTargets=[]\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Checking each row\n",
    "    for i,row in enumerate(rows):\n",
    "        row=row.replace(\"\\n\",\"\")\n",
    "        row=row.split(\",\")\n",
    "        \n",
    "        visualize(i+1,totalImage,row[0],round(time.time()-start_time,2))\n",
    "        \n",
    "        flatPoints=row[3:]\n",
    "        \n",
    "        points=[]\n",
    "        for i in range(0,41,2):\n",
    "            points.append((int(flatPoints[i]),int(flatPoints[i+1])))\n",
    "        # Appending the relative file name\n",
    "        filenames.append(row[0])\n",
    "        \n",
    "        targets.append(points)\n",
    "        tempTargets.append(tuple(points[0]+points[8]))\n",
    "        \n",
    "        img=cv2.imread(os.path.join(PATH,row[0]))\n",
    "        img=cv2.resize(img, (300, 300))\n",
    "        data.append(img)\n",
    "        \n",
    "    return filenames,data,targets,tempTargets\n",
    "\n",
    "# Progress Visualization block\n",
    "def visualize(count,total,filename,execTime):\n",
    "    filename=filename+(40-len(filename))*\" \"\n",
    "    clear_output(wait=True)\n",
    "    prog=(40*count)//total\n",
    "    percent=(count*100)//total\n",
    "    line=\"{}/{} [{}{}] {}%\".format(count,total,\"#\"*prog,\"-\"*(40-prog),percent)\n",
    "    print(\"Analyzing {} | Running for {}s \\n{}\\r\".format(filename,execTime,line))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d1b686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:54:55.537250Z",
     "iopub.status.busy": "2022-12-19T10:54:55.536845Z",
     "iopub.status.idle": "2022-12-19T10:55:15.777596Z",
     "shell.execute_reply": "2022-12-19T10:55:15.776708Z",
     "shell.execute_reply.started": "2022-12-19T10:54:55.537215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing z/hand5_z_dif_seg_5_cropped.jpeg         | Running for 20.21s \n",
      "2518/2518 [########################################] 100%\n"
     ]
    }
   ],
   "source": [
    "filenames,data,alltarget,targets=load_CSV(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add6b8e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:55:23.594836Z",
     "iopub.status.busy": "2022-12-19T10:55:23.594193Z",
     "iopub.status.idle": "2022-12-19T10:55:24.610381Z",
     "shell.execute_reply": "2022-12-19T10:55:24.609317Z",
     "shell.execute_reply.started": "2022-12-19T10:55:23.594794Z"
    }
   },
   "outputs": [],
   "source": [
    "# downsizing and convertion to numpy array\n",
    "# print(targets)\n",
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "targets = np.array(targets, dtype=\"float32\")\n",
    "# print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7126b254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:55:26.640197Z",
     "iopub.status.busy": "2022-12-19T10:55:26.639405Z",
     "iopub.status.idle": "2022-12-19T10:55:27.422165Z",
     "shell.execute_reply": "2022-12-19T10:55:27.421079Z",
     "shell.execute_reply.started": "2022-12-19T10:55:26.640148Z"
    }
   },
   "outputs": [],
   "source": [
    "# the data for training and the remaining 10% for testing\n",
    "trainImages,testImages,trainTargets,testTargets,trainFilenames,testFilenames = train_test_split(data, targets, filenames, test_size=0.10,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a01504d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:55:30.131397Z",
     "iopub.status.busy": "2022-12-19T10:55:30.130672Z",
     "iopub.status.idle": "2022-12-19T10:55:30.137452Z",
     "shell.execute_reply": "2022-12-19T10:55:30.136265Z",
     "shell.execute_reply.started": "2022-12-19T10:55:30.131359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266 252\n",
      "2266 252\n",
      "2266 252\n",
      "(2266, 300, 300, 3)\n",
      "(2266, 4)\n"
     ]
    }
   ],
   "source": [
    "print(len(trainImages),len(testImages))\n",
    "print(len(trainTargets), len(testTargets))\n",
    "print(len(trainFilenames), len(testFilenames))\n",
    "print(trainImages.shape)\n",
    "print(trainTargets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b7d1c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:42:43.819440Z",
     "iopub.status.busy": "2022-12-19T10:42:43.818432Z",
     "iopub.status.idle": "2022-12-19T10:42:43.837262Z",
     "shell.execute_reply": "2022-12-19T10:42:43.836088Z",
     "shell.execute_reply.started": "2022-12-19T10:42:43.819400Z"
    }
   },
   "outputs": [],
   "source": [
    "# KPD23 - Key Point Detection\n",
    "def kpd23():\n",
    "    model=Sequential()\n",
    "    model.add(keras.Input(shape=(300, 300, 3)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same',activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same',activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))\n",
    "              \n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))\n",
    "    \n",
    "               \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(MaxPool2D(pool_size = (2,2), strides= (2,2)))\n",
    "                         \n",
    "    model.add(Conv2D(filters = 1024, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Conv2D(filters = 1024, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Conv2D(filters = 1024, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(MaxPool2D(pool_size = (2,2), strides= (2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units = 1024, activation = \"relu\"))\n",
    "    model.add(Dense(units = 512, activation = \"relu\"))\n",
    "    model.add(Dense(units = 256, activation = \"relu\"))\n",
    "    model.add(Dense(units = 64, activation = \"relu\"))\n",
    "    model.add(Dense(units = 4, activation = \"sigmoid\"))\n",
    "    \n",
    "    optimizer = Adam(lr = 0.0001)\n",
    "    model.compile(optimizer = optimizer, loss=\"mse\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0557a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:42:47.898396Z",
     "iopub.status.busy": "2022-12-19T10:42:47.897906Z",
     "iopub.status.idle": "2022-12-19T10:42:51.578254Z",
     "shell.execute_reply": "2022-12-19T10:42:51.576925Z",
     "shell.execute_reply.started": "2022-12-19T10:42:47.898343Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 10:42:48.048242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.049184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.152669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.153568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.154369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.155164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.157226: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-19 10:42:48.409972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.410881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.411692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.412441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.413213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:48.413965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:51.002887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:51.003887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:51.004663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:51.005367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:51.006144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:51.006868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-12-19 10:42:51.010006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:42:51.010731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 300, 300, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 150, 150, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 18, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 18, 18, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 18, 18, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              84935680  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 116,839,812\n",
      "Trainable params: 116,839,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=kpd23()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4326fd40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:42:55.817116Z",
     "iopub.status.busy": "2022-12-19T10:42:55.816488Z",
     "iopub.status.idle": "2022-12-19T10:53:56.231633Z",
     "shell.execute_reply": "2022-12-19T10:53:56.228472Z",
     "shell.execute_reply.started": "2022-12-19T10:42:55.817068Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 10:42:55.832666: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2447280000 exceeds 10% of free system memory.\n",
      "2022-12-19 10:42:59.667361: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2447280000 exceeds 10% of free system memory.\n",
      "2022-12-19 10:43:01.636128: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 10:43:03.830557: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 107s 1s/step - loss: 31521.1660 - val_loss: 31661.9277\n",
      "Epoch 2/25\n",
      "71/71 [==============================] - 61s 860ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 3/25\n",
      "71/71 [==============================] - 62s 874ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 4/25\n",
      "71/71 [==============================] - 62s 872ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 5/25\n",
      "71/71 [==============================] - 62s 877ms/step - loss: 31512.1582 - val_loss: 31661.9277\n",
      "Epoch 6/25\n",
      "71/71 [==============================] - 62s 875ms/step - loss: 31512.1523 - val_loss: 31661.9277\n",
      "Epoch 7/25\n",
      "71/71 [==============================] - 62s 874ms/step - loss: 31512.1445 - val_loss: 31661.9277\n",
      "Epoch 8/25\n",
      "71/71 [==============================] - 62s 875ms/step - loss: 31512.1484 - val_loss: 31661.9277\n",
      "Epoch 9/25\n",
      "71/71 [==============================] - 62s 875ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 10/25\n",
      "60/71 [========================>.....] - ETA: 9s - loss: 31552.0508 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3210/1504837885.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m history = model.fit(trainImages, trainTargets,validation_data=(testImages, testTargets),\n\u001b[0;32m----> 5\u001b[0;31m               batch_size=BATCH_SIZE,epochs=EPOCH,verbose=1)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH=25\n",
    "BATCH_SIZE=32\n",
    "\n",
    "history = model.fit(trainImages, trainTargets,validation_data=(testImages, testTargets),\n",
    "              batch_size=BATCH_SIZE,epochs=EPOCH,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bef878",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(testImages)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6849e493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:55:41.136379Z",
     "iopub.status.busy": "2022-12-19T10:55:41.135978Z",
     "iopub.status.idle": "2022-12-19T11:06:12.819364Z",
     "shell.execute_reply": "2022-12-19T11:06:12.818197Z",
     "shell.execute_reply.started": "2022-12-19T10:55:41.136344Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 10:55:41.301632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.302673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.408172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.409111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.409881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.410606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.412826: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-19 10:55:41.651784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.652635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.653429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.654453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.655207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:41.655925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:44.481304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:44.482328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:44.483104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:44.483835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:44.484537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:44.485197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-12-19 10:55:44.488457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 10:55:44.489183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300, 300, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               5308544   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 20,033,700\n",
      "Trainable params: 5,319,012\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "[INFO] training bounding box regressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 10:55:45.449150: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2447280000 exceeds 10% of free system memory.\n",
      "2022-12-19 10:55:48.311729: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2447280000 exceeds 10% of free system memory.\n",
      "2022-12-19 10:55:50.225128: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 10:55:52.199088: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 55s 516ms/step - loss: 31515.6816 - val_loss: 31661.9277\n",
      "Epoch 2/25\n",
      "71/71 [==============================] - 21s 296ms/step - loss: 31512.1523 - val_loss: 31661.9277\n",
      "Epoch 3/25\n",
      "71/71 [==============================] - 22s 305ms/step - loss: 31512.1582 - val_loss: 31661.9277\n",
      "Epoch 4/25\n",
      "71/71 [==============================] - 21s 301ms/step - loss: 31512.1484 - val_loss: 31661.9277\n",
      "Epoch 5/25\n",
      "71/71 [==============================] - 21s 299ms/step - loss: 31512.1582 - val_loss: 31661.9277\n",
      "Epoch 6/25\n",
      "71/71 [==============================] - 21s 299ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 7/25\n",
      "71/71 [==============================] - 21s 300ms/step - loss: 31512.1523 - val_loss: 31661.9277\n",
      "Epoch 8/25\n",
      "71/71 [==============================] - 21s 302ms/step - loss: 31512.1484 - val_loss: 31661.9277\n",
      "Epoch 9/25\n",
      "71/71 [==============================] - 21s 301ms/step - loss: 31512.1484 - val_loss: 31661.9277\n",
      "Epoch 10/25\n",
      "71/71 [==============================] - 21s 303ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 11/25\n",
      "71/71 [==============================] - 21s 303ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 12/25\n",
      "71/71 [==============================] - 21s 302ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 13/25\n",
      "71/71 [==============================] - 21s 303ms/step - loss: 31512.1582 - val_loss: 31661.9277\n",
      "Epoch 14/25\n",
      "71/71 [==============================] - 21s 302ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 15/25\n",
      "71/71 [==============================] - 21s 301ms/step - loss: 31512.1523 - val_loss: 31661.9277\n",
      "Epoch 16/25\n",
      "71/71 [==============================] - 21s 300ms/step - loss: 31512.1523 - val_loss: 31661.9277\n",
      "Epoch 17/25\n",
      "71/71 [==============================] - 21s 302ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 18/25\n",
      "71/71 [==============================] - 21s 301ms/step - loss: 31512.1582 - val_loss: 31661.9277\n",
      "Epoch 19/25\n",
      "71/71 [==============================] - 21s 302ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 20/25\n",
      "71/71 [==============================] - 21s 302ms/step - loss: 31512.1523 - val_loss: 31661.9277\n",
      "Epoch 21/25\n",
      "71/71 [==============================] - 21s 301ms/step - loss: 31512.1523 - val_loss: 31661.9277\n",
      "Epoch 22/25\n",
      "71/71 [==============================] - 21s 302ms/step - loss: 31512.1562 - val_loss: 31661.9277\n",
      "Epoch 23/25\n",
      "71/71 [==============================] - 21s 301ms/step - loss: 31512.1582 - val_loss: 31661.9277\n",
      "Epoch 24/25\n",
      "71/71 [==============================] - 21s 300ms/step - loss: 31512.1484 - val_loss: 31661.9277\n",
      "Epoch 25/25\n",
      "71/71 [==============================] - 21s 302ms/step - loss: 31512.1523 - val_loss: 31661.9277\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(300, 300, 3)))\n",
    "# freeze all VGG layers so they will *not* be updated during the\n",
    "# training process\n",
    "vgg.trainable = False\n",
    "# flatten the max-pooling output of VGG\n",
    "flatten = vgg.output\n",
    "flatten = Flatten()(flatten)\n",
    "# construct a fully-connected layer header to output the predicted\n",
    "# bounding box coordinates\n",
    "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
    "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
    "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
    "bboxHead = Dense(4, activation=\"sigmoid\")(bboxHead)\n",
    "# construct the model we will fine-tune for bounding box regression\n",
    "model = Model(inputs=vgg.input, outputs=bboxHead)\n",
    "# initialize the optimizer, compile the model, and show the model\n",
    "# summary\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(loss=\"mse\", optimizer=opt)\n",
    "print(model.summary())\n",
    "# train the network for bounding box regression\n",
    "print(\"[INFO] training bounding box regressor...\")\n",
    "H = model.fit(trainImages, trainTargets,\n",
    "              validation_data=(testImages, testTargets),\n",
    "              batch_size=32,\n",
    "              epochs=25,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79613de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T11:06:23.591950Z",
     "iopub.status.busy": "2022-12-19T11:06:23.591438Z",
     "iopub.status.idle": "2022-12-19T11:06:24.073704Z",
     "shell.execute_reply": "2022-12-19T11:06:24.072523Z",
     "shell.execute_reply.started": "2022-12-19T11:06:23.591892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving object detector model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(\"./model_vgg.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3abcc0e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T11:07:08.321306Z",
     "iopub.status.busy": "2022-12-19T11:07:08.320400Z",
     "iopub.status.idle": "2022-12-19T11:07:12.044629Z",
     "shell.execute_reply": "2022-12-19T11:07:12.043446Z",
     "shell.execute_reply.started": "2022-12-19T11:07:08.321250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 1.       , 1.       , 1.       ],\n",
       "       [1.       , 1.       , 1.       , 1.       ],\n",
       "       [1.       , 1.       , 1.       , 1.       ],\n",
       "       ...,\n",
       "       [1.       , 1.       , 1.       , 1.       ],\n",
       "       [1.       , 1.       , 1.       , 1.       ],\n",
       "       [1.       , 1.       , 0.9999999, 1.       ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(testImages)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "testTargets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
